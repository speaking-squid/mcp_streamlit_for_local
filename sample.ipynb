{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from datetime import datetime\n",
    "from typing import Optional\n",
    "import pytz\n",
    "\n",
    "@tool\n",
    "def get_current_time(timezone: Optional[str] = \"Asia/Seoul\") -> str:\n",
    "    \"\"\"현재 시간 정보를 가져옵니다 (기본: Asia/Seoul).\"\"\"\n",
    "    tz = pytz.timezone(timezone)\n",
    "    now = datetime.now(tz)\n",
    "    return now.strftime(\"%Y-%m-%d %H:%M:%S %Z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "import os\n",
    "\n",
    "# 도구를 OpenAI tool 형식으로 변환\n",
    "tool_schema = convert_to_openai_tool(get_current_time)\n",
    "\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\", None)\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\", None)\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\", None)\n",
    "api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2025-01-01-preview\")\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    deployment_name=deployment_name,\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=endpoint,\n",
    "    api_version=api_version\n",
    ")\n",
    "\n",
    "response = llm.invoke(\n",
    "    [HumanMessage(content=\"현재 서울 시간이 몇시야?\")],\n",
    "    config=RunnableConfig(),\n",
    "    tools=[tool_schema]\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "print(json.dumps(response.additional_kwargs, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"qwq\")\n",
    "\n",
    "response = llm.invoke(\"Hello, world!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, the user said \"Hello, world!\" which is a common first program in programming. I should respond politely. Let me think of a friendly reply. Maybe ask how I can assist them today? That\\'s standard but works. Keep it simple and open-ended. Alright, go with that.\\n</think>\\n\\nHello! It\\'s great to see you. How can I assist you today?'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
